{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE- Gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Minority Oversampling Technique (SMOTE) with 'gini' as criterion for best split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing important libraries and modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split # to split the data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data into dataframe. Extracting the features and class varibales as well as fraud data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('https://people.rit.edu/~hvp4259/project/data/creditcard.csv')\n",
    "print(data.shape)\n",
    "X = data.drop(['Class'], axis=1)\n",
    "y = data['Class']\n",
    "fraud_record = data[data.Class == 1]\n",
    "y_fraud_record = fraud_record.drop(['Class'], axis=1)\n",
    "x_fraud_record = fraud_record['Class']\n",
    "number_records_fraud = len(data.loc[data['Class']==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the utility function called plot_confusion_matrix for displaying the confusion matrix in a nice UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the utility function called show_data for displaying precision, recall and accuracy from the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_data(cm, print_res = 0):\n",
    "    tp = cm[1,1]\n",
    "    fn = cm[1,0]\n",
    "    fp = cm[0,1]\n",
    "    tn = cm[0,0]\n",
    "    if print_res == 1:\n",
    "        print('Precision =     {:.5f}'.format(tp/(tp+fp)))\n",
    "        print('Recall (TPR) =  {:.5f}'.format(tp/(tp+fn)))\n",
    "        print('Accuracy =  {:.5f}'.format((tp+tn)/(tp+tn+fp+fn)))\n",
    "    return tp/(tp+fp), tp/(tp+fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definign the utility function called data_preparation for splitting the data into test and trainign datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepration(x):\n",
    "    x_features= x.drop(['Class'], axis=1)\n",
    "    x_labels=x['Class']\n",
    "    x_features_train,x_features_test,x_labels_train,x_labels_test = train_test_split(x_features,x_labels,test_size=0.3)\n",
    "    print(\"length of training data\")\n",
    "    print(len(x_features_train))\n",
    "    print(\"length of test data\")\n",
    "    print(len(x_features_test))\n",
    "    return(x_features_train,x_features_test,x_labels_train,x_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data, splitting it into test and training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training data\n",
      "199364\n",
      "length of test data\n",
      "85443\n",
      "Proportion of Normal data in training data is  0.9982143215425051\n",
      "Proportion of fraud data in training data is  0.0017856784574948336\n"
     ]
    }
   ],
   "source": [
    "data_train_X,data_test_X,data_train_y,data_test_y=data_prepration(data)\n",
    "columns = data_train_X.columns\n",
    "print(\"Proportion of Normal data in training data is \",len(data_train_y[data_train_y==0])/len(data_train_X))\n",
    "print(\"Proportion of fraud data in training data is \",len(data_train_y[data_train_y==1])/len(data_train_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling the highly disbalanced prepared data and balancing the training dataset with the nornal : fraud data ratio 0.5 : 0.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  398016\n",
      "Number of normal transcation in oversampled data 199008\n",
      "Number of fraud transcation 199008\n",
      "Proportion of Normal data in oversampled data is  0.5\n",
      "Proportion of fraud data in oversampled data is  0.5\n"
     ]
    }
   ],
   "source": [
    "os = SMOTE(random_state = 0)\n",
    "os_data_X, os_data_y = os.fit_sample(data_train_X, data_train_y.values.ravel())\n",
    "os_data_X = pd.DataFrame(data = os_data_X, columns = columns )\n",
    "os_data_y = pd.DataFrame(data = os_data_y, columns = [\"Class\"])\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of normal transcation in oversampled data\",len(os_data_y[os_data_y[\"Class\"]==0]))\n",
    "print(\"Number of fraud transcation\",len(os_data_y[os_data_y[\"Class\"]==1]))\n",
    "print(\"Proportion of Normal data in oversampled data is \",len(os_data_y[os_data_y[\"Class\"]==0])/len(os_data_X))\n",
    "print(\"Proportion of fraud data in oversampled data is \",len(os_data_y[os_data_y[\"Class\"]==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model with RandomForestClassifier having 100 trees in the forest with criterion for best split as 'gini'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'max_depth' : [2000,4000, 6000, 8000, 10000],\n",
    "    'min_samples_split':[1000,5000,10000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CV_clf = GridSearchCV(estimator=clf, param_grid=param_grid, cv= 5)\n",
    "#CV_clf.fit(os_data_X, os_data_y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10000, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=1000,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 100, criterion = 'gini', max_features= 'sqrt', max_depth=10000, min_samples_split=1000)\n",
    "clf.fit(os_data_X, os_data_y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving all 100 trees to the local drive in .dot format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#i_tree = 0\n",
    "#for tree_in_forest in clf.estimators_:\n",
    " #   with open('F:/RIT/Sem 2/AT/random_forest_gini/tree_' + str(i_tree) + '.dot', 'w') as my_file:\n",
    " #     my_file = tree.export_graphviz(tree_in_forest, out_file = my_file)\n",
    "#    i_tree = i_tree + 1'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the model on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(data_test_X)\n",
    "cm = confusion_matrix(data_test_y.values.ravel(), pred)\n",
    "print(cm)\n",
    "plot_confusion_matrix(cm, ['0', '1'], title = 'Confusion Matrix- Test Data')\n",
    "pr, tpr = show_data(cm, print_res = 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the model on the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X)\n",
    "cm = confusion_matrix(y, pred)\n",
    "print(cm)\n",
    "plot_confusion_matrix(cm, ['0', '1'], title = 'Confusion Matrix- Entire Dataset')\n",
    "pr, tpr = show_data(cm, print_res = 1);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
